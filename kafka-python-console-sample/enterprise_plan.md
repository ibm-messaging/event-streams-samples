# IBM Message Hub Kafka Python console sample application: Enterprise Plan
This Python console application demonstrates how to connect to [IBM Message Hub](https://console.ng.bluemix.net/docs/services/MessageHub/index.html), send and receive messages using the [confluent-kafka-python](https://github.com/confluentinc/confluent-kafka-python) library. It also shows how to create and list topics using the Message Hub Admin REST API.

This tutorial will explain how to run the sample app in [Docker](https://docs.docker.com/) using a Message Hub Service in [IBM Cloud®](https://console.ng.bluemix.net/). We package the sample in docker this way to control the environment and allow SNI headers to be supported. It is also possible to host the application locally and still target your Message Hub Service running in IBM Cloud but that is not covered during this tutorial.

## Prerequisites
To build and run the sample, you must have the following:
* [Docker](https://docs.docker.com/) installed
* Provision a [Message Hub Service Instance](https://console.ng.bluemix.net/catalog/services/message-hub/) in [IBM Cloud®](https://console.ng.bluemix.net/ss)

## Get Service Credentials from your Service
You will need to obtain  the values for `<kafka_brokers_sasl>`, `<kafka_admin_url>`, `<user>` and `<password>`, so that they can be passed into the application later. To do this, access your Message Hub instance in the [Bluemix UI](console.bluemix.net/dashboard/apps), go to the Service Credentials tab and select the Credentials you want to use.

**Note:** <kafka_brokers_sasl> must be a single string enclosed in quotes. For example: "host1:port1,host2:port2". We recommend using all the Kafka hosts listed in the Credentials you selected.

## Build and run the sample using Docker
Build the docker container from the same directory as the `Dockerfile`:
```
docker build -t kafka-python-console-sample .
```

Issue the following command with your service credentials to run the sample:
```
docker run --rm -it <container_name> <kafka_brokers_sasl> <kafka_admin_url> <user>:<password> /etc/ssl/certs
```

Alternatively, you can run only the producer or only the consumer by respectively appending the switches -producer or -consumer to the command above.

The sample will run indefinitely until interrupted. To stop the process, use Ctrl+C, for example.

**Note:** The final parameter that is passed in is the `<ca_location>`. This is the path where the trusted SSL certificates are stored on your machine and is therefore system dependent. For example:

* Ubuntu (Used for this example): /etc/ssl/certs
* RedHat: /etc/pki/tls/cert.pem
* macOS: The .pem file you created in the prerequisite section

## Sample Output
Below is a snippet of the output generated by the sample:

```
Kafka Endpoints: kafka01-prod01.messagehub.services.us-south.bluemix.net:9093
Admin REST Endpoint: https://kafka-admin-prod01.messagehub.services.us-south.bluemix.net:443
Creating the topic kafka-python-console-sample-topic with Admin REST API
{}
Admin REST Listing Topics:
[{"name":"kafka-python-console-sample-topic","partitions":1,"retentionMs":"86400000","markedForDeletion":false}]
This sample app will run until interrupted.
The producer has started
The consumer has started
Message produced, offset: 0
Message produced, offset: 2
No messages consumed
Message produced, offset: 3
No messages consumed
Message produced, offset: 4
Message consumed: topic=kafka-python-console-sample-topic, partition=0, offset=4, key=key, value=This is a test message #4
Message produced, offset: 5
No messages consumed
Message produced, offset: 6
Message consumed: topic=kafka-python-console-sample-topic, partition=0, offset=5, key=key, value=This is a test message #5
Message produced, offset: 7
No messages consumed
Message produced, offset: 8
Message consumed: topic=kafka-python-console-sample-topic, partition=0, offset=6, key=key, value=This is a test message #6
```